import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from classifier import Classifier
diabetes_dataset = pd.read_csv('F:\packagesPyPi\AlgoMaster\diabetes.csv')
X = diabetes_dataset.drop(["Pregnancies","BloodPressure","SkinThickness","Outcome"], axis=1)
Y = diabetes_dataset['Outcome']
# X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=30)
# data=LogisticRegression()
# data.fit(X_train,Y_train)
# y_pred=data.predict(X_test)
# acc = accuracy_score(Y_test, y_pred)
# print("1st",acc)

# X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=30)
# data=LogisticRegression()
# data.fit(X_train,Y_train)
# y_pred=data.predict(X_test)
# acc = accuracy_score(Y_test, y_pred)
# print("2nd",acc)

# data=LogisticRegression()
# data.fit(X_train,Y_train)
# y_pred=data.predict(X_test)
# acc = accuracy_score(Y_test, y_pred)
# print("3rd",acc)
clg=Classifier(X,Y,0.2,30)
# print(clg.demo())
# print(clg.model_training())
# print(clg.ensemble_prediction(4))

print(clg.hyperparameter_tuning())
data=(148,0,33.6,0.627,50)
# pred, acc=clg.AdaBoost_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.logistic_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.KNeighbors_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.GaussianNB_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.Bagging_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.ExtraTrees_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.Ridge_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.SGD_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.RandomForest_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.XGB_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.GaussianNB_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.GradientBoosting_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.DecisionTree_test(data)
# print(pred)
# print(acc)

# pred,acc =clg.SVC_test(data)
# print(pred)
# print(acc)

pred=clg.logistic_hyperparameter(data)
print(pred)
# pred,acc=clg.knn_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.gaussian_nb_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.bernoulli_nb_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.bagging_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.extra_trees_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.ridge_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.sgd_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.random_forest_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.xgb_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.ada_boost_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.gradient_boosting_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.decision_tree_hyperparameter(data)
# print(pred)
# print(acc)
# pred,acc=clg.svc_hyperparameter(data)
# print(pred)
# print(acc)